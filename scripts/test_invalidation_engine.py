#!/usr/bin/env python3
# æ¡ä»¶æ€§å¤±æ•ˆè§„åˆ™å¼•æ“æµ‹è¯•è„šæœ¬

import asyncio
import logging
import sys
import os
from datetime import datetime, timezone, timedelta

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'backend'))

from app.services.temporal_graphiti_service import TemporalGraphitiService
from app.services.conditional_invalidation_engine import (
    ConditionalInvalidationEngine, 
    InvalidationRule, 
    RuleCondition,
    RuleOperator,
    RuleConditionType
)
from app.models.temporal_schemas import TemporalEventType, TemporalValidityState

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def test_conditional_invalidation_engine():
    """æµ‹è¯•æ¡ä»¶æ€§å¤±æ•ˆè§„åˆ™å¼•æ“"""
    service = TemporalGraphitiService()
    
    try:
        logger.info("ğŸš€ Initializing TemporalGraphitiService...")
        await service.initialize()
        
        invalidation_engine = service.transition_engine.invalidation_engine
        logger.info("âœ… Service initialized with invalidation engine")
        
        # === æµ‹è¯•åœºæ™¯1: æ•…éšœè‡ªåŠ¨å¤±æ•ˆè§„åˆ™ ===
        logger.info("\nğŸ“ æµ‹è¯•åœºæ™¯1: æ•…éšœäº‹ä»¶åœ¨æœåŠ¡æ¢å¤åè‡ªåŠ¨å¤±æ•ˆ")
        
        # åˆ›å»ºæ•…éšœäº‹ä»¶
        fault_event_data = {
            'name': 'API Gateway Timeout Fault',
            'description': 'API Gateway experiencing high latency and timeouts',
            'event_type': 'fault_occurrence',
            'category': 'api_fault',
            'source_system': 'api_monitor',
            'occurrence_time': datetime.now(timezone.utc).isoformat(),
            'validity_start': datetime.now(timezone.utc).isoformat(),
            'custom_properties': {
                'service_name': 'api-gateway',
                'severity': 'high',
                'error_rate': 0.15,
                'incident_id': 'INC-2025-002'
            }
        }
        
        fault_event_id = await service.create_temporal_event(fault_event_data)
        logger.info(f"âœ… Created fault event: {fault_event_id}")
        
        # æ‰‹åŠ¨è®¾ç½®äº‹ä»¶ä¸ºæœ‰æ•ˆçŠ¶æ€
        await service.manual_state_change(
            fault_event_id, 'valid', 
            'Fault confirmed by monitoring', 
            'test_system'
        )
        
        # åˆ›å»ºæ¢å¤äº‹ä»¶
        recovery_event_data = {
            'name': 'API Gateway Recovery Process',
            'description': 'Implementing load balancer reconfiguration',
            'event_type': 'recovery_process',
            'category': 'service_recovery',
            'source_system': 'sre_team',
            'occurrence_time': (datetime.now(timezone.utc) + timedelta(minutes=2)).isoformat(),
            'validity_start': (datetime.now(timezone.utc) + timedelta(minutes=2)).isoformat(),
            'custom_properties': {
                'target_service': 'api-gateway',
                'recovery_action': 'load_balancer_config',
                'operator': 'sre_team'
            }
        }
        
        recovery_event_id = await service.create_temporal_event(recovery_event_data)
        await service.manual_state_change(
            recovery_event_id, 'valid',
            'Recovery process started',
            'sre_team'
        )
        logger.info(f"âœ… Created recovery event: {recovery_event_id}")
        
        # æµ‹è¯•æ¡ä»¶æ€§å¤±æ•ˆè¯„ä¼°
        logger.info("ğŸ” è¯„ä¼°æ•…éšœäº‹ä»¶çš„å¤±æ•ˆæ¡ä»¶...")
        invalidation_result = await invalidation_engine.process_event_invalidation(
            fault_event_id,
            {'simulated_recovery_check': True}
        )
        logger.info(f"Invalidation result: {invalidation_result}")
        
        # === æµ‹è¯•åœºæ™¯2: å‘Šè­¦è¶…æ—¶å¤±æ•ˆè§„åˆ™ ===
        logger.info("\nğŸ“ æµ‹è¯•åœºæ™¯2: å‘Šè­¦è¶…æ—¶è‡ªåŠ¨å¤±æ•ˆ")
        
        # åˆ›å»ºä¸€ä¸ªè¿‡æœŸå‘Šè­¦äº‹ä»¶ï¼ˆæ¨¡æ‹Ÿ7å°æ—¶å‰çš„å‘Šè­¦ï¼‰
        old_alert_time = datetime.now(timezone.utc) - timedelta(hours=7)
        alert_event_data = {
            'name': 'Database Connection Pool Alert',
            'description': 'Database connection pool utilization high',
            'event_type': 'alert_lifecycle',
            'category': 'performance_alert',
            'source_system': 'db_monitor',
            'occurrence_time': old_alert_time.isoformat(),
            'validity_start': old_alert_time.isoformat(),
            'custom_properties': {
                'alert_type': 'threshold_breach',
                'metric': 'connection_pool_utilization',
                'threshold': 90,
                'current_value': 95
            }
        }
        
        alert_event_id = await service.create_temporal_event(alert_event_data)
        await service.manual_state_change(
            alert_event_id, 'valid',
            'Alert triggered by threshold breach',
            'monitoring_system'
        )
        logger.info(f"âœ… Created old alert event: {alert_event_id}")
        
        # æµ‹è¯•è¶…æ—¶å¤±æ•ˆè§„åˆ™
        logger.info("â° æµ‹è¯•å‘Šè­¦è¶…æ—¶å¤±æ•ˆè§„åˆ™...")
        alert_invalidation_result = await invalidation_engine.process_event_invalidation(
            alert_event_id,
            {'timeout_check': True}
        )
        logger.info(f"Alert timeout result: {alert_invalidation_result}")
        
        # === æµ‹è¯•åœºæ™¯3: è‡ªå®šä¹‰å¤±æ•ˆè§„åˆ™ ===
        logger.info("\nğŸ“ æµ‹è¯•åœºæ™¯3: è‡ªå®šä¹‰å¤±æ•ˆè§„åˆ™")
        
        # æ·»åŠ è‡ªå®šä¹‰è§„åˆ™ï¼šCPUä½¿ç”¨ç‡æ¢å¤æ­£å¸¸åå¤±æ•ˆç›¸å…³äº‹ä»¶
        custom_rule = InvalidationRule(
            rule_id="cpu_normalized_invalidation",
            name="CPUä½¿ç”¨ç‡æ¢å¤æ­£å¸¸å¤±æ•ˆè§„åˆ™",
            description="å½“CPUä½¿ç”¨ç‡ä½äº10%å¹¶æŒç»­5åˆ†é’Ÿåï¼Œç›¸å…³æ€§èƒ½äº‹ä»¶è‡ªåŠ¨å¤±æ•ˆ",
            conditions=[
                RuleCondition(
                    condition_id="cpu_usage_low",
                    condition_type=RuleConditionType.METRIC_BASED,
                    operator=RuleOperator.LESS_THAN,
                    field_path="custom_properties.current_cpu_usage",
                    expected_value=10.0,
                    description="æ£€æŸ¥CPUä½¿ç”¨ç‡æ˜¯å¦ä½äº10%"
                ),
                RuleCondition(
                    condition_id="stable_duration",
                    condition_type=RuleConditionType.TIME_BASED,
                    operator=RuleOperator.GREATER_THAN,
                    field_path="custom_properties.stable_since",
                    expected_value=300,  # 5åˆ†é’Ÿ
                    description="æ£€æŸ¥ç¨³å®šæŒç»­æ—¶é—´"
                )
            ],
            logical_operator=RuleOperator.AND,
            applicable_event_types=["impact_observation"],
            applicable_categories=["performance_monitoring"],
            priority=1
        )
        
        invalidation_engine.add_rule(custom_rule)
        logger.info("âœ… Added custom invalidation rule")
        
        # åˆ›å»ºæ€§èƒ½ç›‘æ§äº‹ä»¶
        perf_event_data = {
            'name': 'High CPU Usage Observation',
            'description': 'CPU usage spike detected on application servers',
            'event_type': 'impact_observation',
            'category': 'performance_monitoring',
            'source_system': 'cpu_monitor',
            'occurrence_time': (datetime.now(timezone.utc) - timedelta(minutes=10)).isoformat(),
            'validity_start': (datetime.now(timezone.utc) - timedelta(minutes=10)).isoformat(),
            'custom_properties': {
                'metric_type': 'cpu_utilization',
                'peak_value': 85.5,
                'current_cpu_usage': 8.5,  # ç°åœ¨å·²æ¢å¤æ­£å¸¸
                'stable_since': (datetime.now(timezone.utc) - timedelta(minutes=8)).isoformat(),
                'threshold': 80
            }
        }
        
        perf_event_id = await service.create_temporal_event(perf_event_data)
        await service.manual_state_change(
            perf_event_id, 'valid',
            'Performance issue confirmed',
            'monitoring_system'
        )
        logger.info(f"âœ… Created performance monitoring event: {perf_event_id}")
        
        # æµ‹è¯•è‡ªå®šä¹‰å¤±æ•ˆè§„åˆ™
        logger.info("ğŸ”§ æµ‹è¯•è‡ªå®šä¹‰å¤±æ•ˆè§„åˆ™...")
        custom_invalidation_result = await invalidation_engine.process_event_invalidation(
            perf_event_id,
            {'metrics_check': True}
        )
        logger.info(f"Custom rule result: {custom_invalidation_result}")
        
        # === æµ‹è¯•åœºæ™¯4: äº‹æ•…å…³é—­çº§è”å¤±æ•ˆ ===
        logger.info("\nğŸ“ æµ‹è¯•åœºæ™¯4: äº‹æ•…å…³é—­çº§è”å¤±æ•ˆ")
        
        # åˆ›å»ºäº‹æ•…è§£å†³äº‹ä»¶
        incident_resolution_data = {
            'name': 'Incident INC-2025-002 Resolution',
            'description': 'API Gateway issue fully resolved and documented',
            'event_type': 'incident_resolution',
            'category': 'incident_management',
            'source_system': 'incident_management',
            'occurrence_time': datetime.now(timezone.utc).isoformat(),
            'validity_start': datetime.now(timezone.utc).isoformat(),
            'custom_properties': {
                'incident_id': 'INC-2025-002',
                'resolution_status': 'closed',
                'root_cause': 'load_balancer_misconfiguration',
                'resolution_time': datetime.now(timezone.utc).isoformat()
            }
        }
        
        incident_resolution_id = await service.create_temporal_event(incident_resolution_data)
        await service.manual_state_change(
            incident_resolution_id, 'valid',
            'Incident officially closed',
            'incident_manager'
        )
        logger.info(f"âœ… Created incident resolution: {incident_resolution_id}")
        
        # æµ‹è¯•çº§è”å¤±æ•ˆï¼ˆåº”è¯¥å¤±æ•ˆæ‰€æœ‰ç›¸å…³çš„æ•…éšœå’Œå‘Šè­¦äº‹ä»¶ï¼‰
        logger.info("ğŸ”— æµ‹è¯•äº‹æ•…å…³é—­çº§è”å¤±æ•ˆ...")
        
        # é‡æ–°è¯„ä¼°æ•…éšœäº‹ä»¶ï¼ˆç°åœ¨åº”è¯¥è¢«çº§è”å¤±æ•ˆï¼‰
        cascade_result = await invalidation_engine.process_event_invalidation(
            fault_event_id,
            {'incident_closure_check': True}
        )
        logger.info(f"Cascade invalidation result: {cascade_result}")
        
        # ç­‰å¾…è‡ªåŠ¨åŒ–ç›‘æ§å¤„ç†
        logger.info("â° Waiting for automated monitoring cycle...")
        await asyncio.sleep(5)
        
        # === è·å–æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯ ===
        logger.info("\nğŸ“Š è·å–å¤±æ•ˆè§„åˆ™æ‰§è¡Œç»Ÿè®¡...")
        
        # è·å–è§„åˆ™ç»Ÿè®¡
        rule_stats = invalidation_engine.get_rule_statistics()
        logger.info(f"Total rule executions: {rule_stats['total_executions']}")
        logger.info(f"Successful executions: {rule_stats['successful_executions']}")
        logger.info(f"Failed executions: {rule_stats['failed_executions']}")
        logger.info(f"Total rules: {rule_stats['total_rules']}")
        logger.info(f"Enabled rules: {rule_stats['enabled_rules']}")
        
        # è·å–æ•´ä½“ç³»ç»Ÿç»Ÿè®¡
        system_stats = await service.get_transition_statistics()
        logger.info(f"Total state transitions: {system_stats['transition_engine']['total_transitions']}")
        
        # æ£€æŸ¥æœ€ç»ˆäº‹ä»¶çŠ¶æ€
        logger.info("\nğŸ“‹ æ£€æŸ¥æœ€ç»ˆäº‹ä»¶çŠ¶æ€...")
        
        events_to_check = [
            ('æ•…éšœäº‹ä»¶', fault_event_id),
            ('æ¢å¤äº‹ä»¶', recovery_event_id), 
            ('å‘Šè­¦äº‹ä»¶', alert_event_id),
            ('æ€§èƒ½ç›‘æ§äº‹ä»¶', perf_event_id),
            ('äº‹æ•…è§£å†³äº‹ä»¶', incident_resolution_id)
        ]
        
        for event_name, event_id in events_to_check:
            lifecycle = await service.get_event_lifecycle(event_id)
            if lifecycle:
                logger.info(f"{event_name}: {lifecycle['current_state']}")
            else:
                logger.warning(f"Failed to get lifecycle for {event_name}")
        
        logger.info("ğŸ‰ Conditional invalidation engine test completed successfully!")
        
        return {
            'rule_statistics': rule_stats,
            'system_statistics': system_stats,
            'test_events': {
                'fault_event_id': fault_event_id,
                'recovery_event_id': recovery_event_id,
                'alert_event_id': alert_event_id,
                'perf_event_id': perf_event_id,
                'incident_resolution_id': incident_resolution_id
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ Test failed: {e}")
        raise
    finally:
        await service.close()

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ”¬ Starting Conditional Invalidation Engine Test")
    
    try:
        test_results = await test_conditional_invalidation_engine()
        
        logger.info("\n" + "="*70)
        logger.info("ğŸ“‹ CONDITIONAL INVALIDATION ENGINE TEST RESULTS")
        logger.info("="*70)
        
        rule_stats = test_results['rule_statistics']
        logger.info(f"âœ… Total Rule Executions: {rule_stats['total_executions']}")
        logger.info(f"âœ… Successful Executions: {rule_stats['successful_executions']}")
        logger.info(f"âŒ Failed Executions: {rule_stats['failed_executions']}")
        logger.info(f"ğŸ“ Total Rules: {rule_stats['total_rules']}")
        logger.info(f"ğŸŸ¢ Enabled Rules: {rule_stats['enabled_rules']}")
        logger.info(f"ğŸ”´ Disabled Rules: {rule_stats['disabled_rules']}")
        
        system_stats = test_results['system_statistics']
        logger.info(f"âš¡ Total State Transitions: {system_stats['transition_engine']['total_transitions']}")
        logger.info(f"ğŸ¤– Automatic Transitions: {system_stats['transition_engine']['automatic_transitions']}")
        logger.info(f"ğŸ‘¤ Manual Transitions: {system_stats['transition_engine']['manual_transitions']}")
        
        logger.info("\nğŸ“ Test Events Created:")
        for event_type, event_id in test_results['test_events'].items():
            logger.info(f"  â€¢ {event_type}: {event_id}")
        
        logger.info("="*70)
        logger.info("ğŸ‰ ALL INVALIDATION ENGINE TESTS PASSED!")
        
    except Exception as e:
        logger.error(f"ğŸ’¥ Tests failed with error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())