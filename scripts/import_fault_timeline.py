#!/usr/bin/env python3
"""
æ•…éšœæ—¶åºäº‹ä»¶å¯¼å…¥è„šæœ¬ - å¯¼å…¥å®Œæ•´çš„æ•…éšœå‘ç”Ÿå’Œæ¢å¤æ—¶é—´çº¿

è¯¥è„šæœ¬ä¸“é—¨å¤„ç†è¿ç»´æ•…éšœåœºæ™¯çš„æ—¶åºäº‹ä»¶ï¼ŒåŒ…æ‹¬ï¼š
- æ•…éšœæ£€æµ‹ä¸å‘Šè­¦ (FaultEvent, Alert)
- å½±å“æ‰©æ•£è§‚æµ‹ (Observation, K8sEvent)
- äº‹æ•…å“åº”æµç¨‹ (IncidentResponse, DiagnosticAction)
- æ¢å¤å¤„ç†è¿‡ç¨‹ (RecoveryAction, RecoveryValidation)
- äº‹æ•…è§£å†³å¤ç›˜ (IncidentResolution, PostMortem)

æ”¯æŒæ—¶åºæŸ¥è¯¢åœºæ™¯ï¼š
1. æ•…éšœå½±å“æ—¶é—´çº¿åˆ†æ
2. å“åº”æ•ˆç‡è¯„ä¼° (MTTD, MTTR)
3. æ ¹å› åˆ†æè·¯å¾„è¿½è¸ª
4. æ¢å¤ç­–ç•¥æœ‰æ•ˆæ€§éªŒè¯
"""

import json
import asyncio
import httpx
from datetime import datetime, timedelta
from pathlib import Path
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# API é…ç½®
API_BASE_URL = "http://localhost:8001"
FAULT_DATA_FILE = "../data/fault_timeline_events.jsonl"

class FaultTimelineImporter:
    def __init__(self, api_base_url: str):
        self.api_base_url = api_base_url
        self.client = httpx.AsyncClient(timeout=30.0)
        
    async def __aenter__(self):
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.client.aclose()

    def parse_fault_events(self, file_path: str):
        """è§£ææ•…éšœæ—¶åºäº‹ä»¶æ–‡ä»¶"""
        events = []
        file_path = Path(__file__).parent / file_path
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        event = json.loads(line)
                        events.append(event)
                    except json.JSONDecodeError as e:
                        logger.warning(f"ç¬¬ {line_num} è¡Œ JSON è§£æé”™è¯¯: {e}")
                        continue
        except FileNotFoundError:
            logger.error(f"æ•…éšœäº‹ä»¶æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
            return []
            
        logger.info(f"æˆåŠŸè§£æ {len(events)} ä¸ªæ•…éšœæ—¶åºäº‹ä»¶")
        return events

    def convert_fault_event_to_knowledge_node(self, event: dict) -> dict:
        """å°†æ•…éšœäº‹ä»¶è½¬æ¢ä¸ºçŸ¥è¯†èŠ‚ç‚¹"""
        op = event.get('op')
        
        if op == 'merge_node':
            node_type = event.get('type', 'Unknown')
            node_id = event.get('id', '')
            properties = event.get('properties', {})
            
            # ç”ŸæˆèŠ‚ç‚¹åç§°å’Œå†…å®¹
            name = self.generate_fault_node_name(node_type, properties)
            content = self.generate_fault_node_content(node_type, properties)
            tkg_type = self.map_fault_node_type(node_type)
            
            # æ—¶åºä¿¡æ¯å¤„ç†
            valid_time = None
            time_str = properties.get('time')
            if time_str:
                try:
                    start_time = datetime.fromisoformat(time_str.replace('Z', '+00:00'))
                    # ä¸ºä¸åŒäº‹ä»¶ç±»å‹è®¾ç½®ä¸åŒçš„æœ‰æ•ˆæœŸ
                    end_time = self.calculate_event_validity_end(node_type, start_time)
                    
                    valid_time = {
                        "start_time": start_time.isoformat(),
                        "end_time": end_time.isoformat() if end_time else None
                    }
                except Exception as e:
                    logger.warning(f"æ—¶é—´è§£æé”™è¯¯: {e}")
            
            return {
                "name": name,
                "type": tkg_type,
                "content": content,
                "properties": {
                    "fault_category": self.get_fault_category(node_type),
                    "original_type": node_type,
                    "original_id": node_id,
                    "source": "æ•…éšœç®¡ç†ç³»ç»Ÿ",
                    "timeline_phase": self.get_timeline_phase(node_type),
                    **properties
                },
                "valid_time": valid_time,
                "effective_time": properties.get('time')
            }
        
        return None

    def map_fault_node_type(self, original_type: str) -> str:
        """æ˜ å°„æ•…éšœèŠ‚ç‚¹ç±»å‹"""
        type_mapping = {
            'FaultEvent': 'event',
            'Alert': 'event', 
            'K8sEvent': 'event',
            'Observation': 'event',
            'IncidentResponse': 'episode',
            'DiagnosticAction': 'episode',
            'RecoveryAction': 'episode',
            'RecoveryValidation': 'episode',
            'IncidentResolution': 'episode',
            'PostMortem': 'concept'
        }
        return type_mapping.get(original_type, 'event')

    def get_fault_category(self, node_type: str) -> str:
        """è·å–æ•…éšœåˆ†ç±»"""
        category_mapping = {
            'FaultEvent': 'æ•…éšœæ£€æµ‹',
            'Alert': 'å‘Šè­¦é€šçŸ¥',
            'K8sEvent': 'K8säº‹ä»¶',
            'Observation': 'ç›‘æ§è§‚æµ‹',
            'IncidentResponse': 'äº‹æ•…å“åº”',
            'DiagnosticAction': 'æ•…éšœè¯Šæ–­',
            'RecoveryAction': 'æ¢å¤å¤„ç†',
            'RecoveryValidation': 'æ¢å¤éªŒè¯',
            'IncidentResolution': 'äº‹æ•…è§£å†³',
            'PostMortem': 'å¤ç›˜åˆ†æ'
        }
        return category_mapping.get(node_type, 'å…¶ä»–')

    def get_timeline_phase(self, node_type: str) -> str:
        """è·å–æ—¶é—´çº¿é˜¶æ®µ"""
        phase_mapping = {
            'FaultEvent': '1-æ•…éšœå‘ç”Ÿ',
            'Alert': '2-å‘Šè­¦è§¦å‘',
            'K8sEvent': '3-ç³»ç»Ÿå“åº”',
            'Observation': '4-å½±å“è§‚æµ‹',
            'IncidentResponse': '5-äº‹æ•…å“åº”',
            'DiagnosticAction': '6-é—®é¢˜è¯Šæ–­',
            'RecoveryAction': '7-æ¢å¤å¤„ç†',
            'RecoveryValidation': '8-æ¢å¤éªŒè¯',
            'IncidentResolution': '9-äº‹æ•…è§£å†³',
            'PostMortem': '10-å¤ç›˜æ€»ç»“'
        }
        return phase_mapping.get(node_type, '0-æœªçŸ¥é˜¶æ®µ')

    def calculate_event_validity_end(self, node_type: str, start_time: datetime) -> datetime:
        """è®¡ç®—äº‹ä»¶æœ‰æ•ˆæœŸç»“æŸæ—¶é—´"""
        duration_mapping = {
            'FaultEvent': timedelta(hours=24),  # æ•…éšœäº‹ä»¶24å°æ—¶æœ‰æ•ˆ
            'Alert': timedelta(hours=1),        # å‘Šè­¦1å°æ—¶æœ‰æ•ˆ
            'K8sEvent': timedelta(minutes=30),  # K8säº‹ä»¶30åˆ†é’Ÿæœ‰æ•ˆ
            'Observation': timedelta(minutes=15), # è§‚æµ‹æ•°æ®15åˆ†é’Ÿæœ‰æ•ˆ
            'IncidentResponse': timedelta(hours=8), # å“åº”8å°æ—¶æœ‰æ•ˆ
            'DiagnosticAction': timedelta(hours=2), # è¯Šæ–­2å°æ—¶æœ‰æ•ˆ
            'RecoveryAction': timedelta(hours=1),   # æ¢å¤1å°æ—¶æœ‰æ•ˆ
            'RecoveryValidation': timedelta(hours=2), # éªŒè¯2å°æ—¶æœ‰æ•ˆ
            'IncidentResolution': timedelta(days=30), # è§£å†³æ–¹æ¡ˆ30å¤©æœ‰æ•ˆ
            'PostMortem': None  # å¤ç›˜é•¿æœŸæœ‰æ•ˆ
        }
        
        duration = duration_mapping.get(node_type)
        return start_time + duration if duration else None

    def generate_fault_node_name(self, node_type: str, properties: dict) -> str:
        """ç”Ÿæˆæ•…éšœèŠ‚ç‚¹åç§°"""
        if node_type == 'FaultEvent':
            fault_id = properties.get('fault_id', 'UNKNOWN')
            fault_type = properties.get('fault_type', 'æœªçŸ¥æ•…éšœ')
            return f"{fault_id}_{fault_type}"
        
        elif node_type == 'Alert':
            alert_type = properties.get('alert_type', 'æœªçŸ¥å‘Šè­¦')
            priority = properties.get('priority', 'P5')
            return f"{priority}_{alert_type}_å‘Šè­¦"
        
        elif node_type == 'IncidentResponse':
            incident_id = properties.get('incident_id', 'UNKNOWN')
            team = properties.get('response_team', 'æœªçŸ¥å›¢é˜Ÿ')
            return f"{incident_id}_{team}_å“åº”"
        
        elif node_type == 'RecoveryAction':
            action_type = properties.get('action_type', 'æ¢å¤åŠ¨ä½œ')
            return f"æ¢å¤æ“ä½œ_{action_type}"
        
        elif node_type == 'PostMortem':
            postmortem_id = properties.get('postmortem_id', 'UNKNOWN')
            return f"{postmortem_id}_å¤ç›˜åˆ†æ"
        
        else:
            service = properties.get('service', 'æœªçŸ¥æœåŠ¡')
            time_str = properties.get('time', '')
            time_part = time_str.split('T')[1][:8] if 'T' in time_str else 'unknown'
            return f"{service}_{node_type}_{time_part}"

    def generate_fault_node_content(self, node_type: str, properties: dict) -> str:
        """ç”Ÿæˆæ•…éšœèŠ‚ç‚¹å†…å®¹æè¿°"""
        service = properties.get('service', 'æœªçŸ¥æœåŠ¡')
        time = properties.get('time', 'æœªçŸ¥æ—¶é—´')
        
        if node_type == 'FaultEvent':
            fault_type = properties.get('fault_type', 'æœªçŸ¥æ•…éšœ')
            severity = properties.get('severity', 'æœªçŸ¥ä¸¥é‡ç¨‹åº¦')
            description = properties.get('description', 'æ— æè¿°')
            impact = properties.get('impact_level', 'æœªçŸ¥å½±å“')
            return f"{time}: {service} å‘ç”Ÿ{severity}çº§æ•…éšœ - {fault_type}ã€‚{description}ã€‚å½±å“çº§åˆ«: {impact}"
        
        elif node_type == 'Alert':
            alert_type = properties.get('alert_type', 'æœªçŸ¥ç±»å‹')
            threshold = properties.get('threshold', 0)
            current_value = properties.get('current_value', 0)
            message = properties.get('message', 'æ— æ¶ˆæ¯')
            return f"{time}: {service} è§¦å‘{alert_type}å‘Šè­¦ã€‚é˜ˆå€¼: {threshold}, å½“å‰å€¼: {current_value}ã€‚{message}"
        
        elif node_type == 'Observation':
            source = properties.get('source', 'æœªçŸ¥æº')
            error_rate = properties.get('error_rate', 0)
            latency = properties.get('latency_ms', 0)
            status = properties.get('status', 'æœªçŸ¥çŠ¶æ€')
            return f"{time}: {source} ç›‘æ§æ˜¾ç¤º {service} é”™è¯¯ç‡ {error_rate:.2%}, å»¶è¿Ÿ {latency}ms, çŠ¶æ€: {status}"
        
        elif node_type == 'IncidentResponse':
            incident_id = properties.get('incident_id', 'æœªçŸ¥äº‹æ•…')
            team = properties.get('response_team', 'æœªçŸ¥å›¢é˜Ÿ')
            priority = properties.get('priority', 'æœªçŸ¥ä¼˜å…ˆçº§')
            impact = properties.get('estimated_impact', 'æœªçŸ¥å½±å“')
            return f"{time}: {incident_id} äº‹æ•…å“åº”å¯åŠ¨ï¼Œ{team} å›¢é˜Ÿæ¥æ‰‹å¤„ç†ã€‚ä¼˜å…ˆçº§: {priority}, é¢„ä¼°å½±å“: {impact}"
        
        elif node_type == 'DiagnosticAction':
            action_type = properties.get('action_type', 'æœªçŸ¥è¯Šæ–­')
            result = properties.get('result', 'æ— ç»“æœ')
            details = properties.get('details', 'æ— è¯¦æƒ…')
            next_action = properties.get('next_action', 'æ— åç»­åŠ¨ä½œ')
            return f"{time}: æ‰§è¡Œ{action_type}è¯Šæ–­ï¼Œç»“æœ: {result}ã€‚{details}ã€‚ä¸‹ä¸€æ­¥: {next_action}"
        
        elif node_type == 'RecoveryAction':
            action_type = properties.get('action_type', 'æœªçŸ¥æ¢å¤')
            status = properties.get('status', 'æœªçŸ¥çŠ¶æ€')
            duration = properties.get('estimated_duration', 'æœªçŸ¥æ—¶é•¿')
            risk = properties.get('risk_level', 'æœªçŸ¥é£é™©')
            return f"{time}: æ‰§è¡Œ{action_type}æ¢å¤æ“ä½œï¼ŒçŠ¶æ€: {status}ï¼Œé¢„è®¡è€—æ—¶: {duration}ï¼Œé£é™©çº§åˆ«: {risk}"
        
        elif node_type == 'RecoveryValidation':
            validation_type = properties.get('validation_type', 'æœªçŸ¥éªŒè¯')
            success_rate = properties.get('success_rate', 0)
            status = properties.get('status', 'æœªçŸ¥çŠ¶æ€')
            test_cases = properties.get('test_cases', [])
            return f"{time}: æ‰§è¡Œ{validation_type}éªŒè¯ï¼ŒæˆåŠŸç‡: {success_rate:.1%}ï¼ŒçŠ¶æ€: {status}ã€‚æµ‹è¯•ç”¨ä¾‹: {', '.join(test_cases)}"
        
        elif node_type == 'IncidentResolution':
            incident_id = properties.get('incident_id', 'æœªçŸ¥äº‹æ•…')
            downtime = properties.get('total_downtime', 'æœªçŸ¥æ—¶é•¿')
            root_cause = properties.get('root_cause', 'æœªçŸ¥æ ¹å› ')
            fix = properties.get('fix_applied', 'æœªçŸ¥ä¿®å¤')
            return f"{time}: {incident_id} äº‹æ•…è§£å†³ï¼Œæ€»åœæœºæ—¶é—´: {downtime}ã€‚æ ¹å› : {root_cause}ã€‚ä¿®å¤æ–¹æ¡ˆ: {fix}"
        
        elif node_type == 'PostMortem':
            incident_id = properties.get('incident_id', 'æœªçŸ¥äº‹æ•…')
            root_cause = properties.get('root_cause_analysis', 'æ— æ ¹å› åˆ†æ')
            prevention = properties.get('prevention_actions', [])
            lessons = properties.get('lessons_learned', 'æ— ç»éªŒæ•™è®­')
            return f"{time}: {incident_id} å¤ç›˜åˆ†æå®Œæˆã€‚æ ¹å› : {root_cause}ã€‚é¢„é˜²æªæ–½: {', '.join(prevention)}ã€‚ç»éªŒæ•™è®­: {lessons}"
        
        elif node_type == 'K8sEvent':
            event_type = properties.get('event_type', 'æœªçŸ¥äº‹ä»¶')
            pod_status = properties.get('pod_status', 'æœªçŸ¥çŠ¶æ€')
            message = properties.get('message', 'æ— æ¶ˆæ¯')
            return f"{time}: {service} K8s {event_type} äº‹ä»¶ï¼ŒPodçŠ¶æ€: {pod_status}ã€‚{message}"
        
        return f"{time}: {service} {node_type} äº‹ä»¶ - {properties}"

    async def create_fault_knowledge_node(self, node_data: dict) -> dict:
        """åˆ›å»ºæ•…éšœçŸ¥è¯†èŠ‚ç‚¹"""
        try:
            response = await self.client.post(
                f"{self.api_base_url}/api/knowledge/",
                json=node_data,
                headers={"Content-Type": "application/json"}
            )
            response.raise_for_status()
            result = response.json()
            
            # è®°å½•è¯¦ç»†çš„åˆ›å»ºä¿¡æ¯
            phase = result.get('properties', {}).get('timeline_phase', 'Unknown')
            category = result.get('properties', {}).get('fault_category', 'Unknown')
            logger.info(f"âœ… åˆ›å»ºèŠ‚ç‚¹: [{phase}] {category} - {result.get('name', '')}")
            return result
        except httpx.HTTPError as e:
            logger.error(f"âŒ åˆ›å»ºèŠ‚ç‚¹å¤±è´¥: {e}")
            return None

    async def import_fault_timeline(self):
        """å¯¼å…¥æ•…éšœæ—¶åºäº‹ä»¶"""
        logger.info("ğŸš€ å¼€å§‹å¯¼å…¥æ•…éšœæ—¶åºäº‹ä»¶æ•°æ®...")
        
        # è§£æäº‹ä»¶æ–‡ä»¶
        events = self.parse_fault_events(FAULT_DATA_FILE)
        if not events:
            logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ•…éšœäº‹ä»¶æ•°æ®")
            return
        
        # åˆ†ç¦»èŠ‚ç‚¹å’Œè¾¹
        nodes = [event for event in events if event.get('op') == 'merge_node']
        edges = [event for event in events if event.get('op') == 'merge_edge']
        
        logger.info(f"ğŸ“Š å‘ç° {len(nodes)} ä¸ªæ—¶åºèŠ‚ç‚¹ï¼Œ{len(edges)} æ¡å› æœå…³ç³»")
        
        # æŒ‰æ—¶é—´æ’åºï¼Œç¡®ä¿æ—¶åºæ­£ç¡®æ€§
        nodes.sort(key=lambda x: x.get('properties', {}).get('time', ''))
        
        # åˆ›å»ºèŠ‚ç‚¹æ˜ å°„
        created_nodes = {}
        timeline_stats = {}
        
        # å¯¼å…¥æ‰€æœ‰æ•…éšœæ—¶åºèŠ‚ç‚¹
        logger.info("ğŸ“… é˜¶æ®µä¸€ï¼šæŒ‰æ—¶é—´é¡ºåºåˆ›å»ºæ•…éšœæ—¶åºèŠ‚ç‚¹...")
        for i, node_event in enumerate(nodes, 1):
            node_data = self.convert_fault_event_to_knowledge_node(node_event)
            if node_data:
                # ç»Ÿè®¡æ—¶é—´çº¿é˜¶æ®µ
                phase = node_data.get('properties', {}).get('timeline_phase', 'Unknown')
                timeline_stats[phase] = timeline_stats.get(phase, 0) + 1
                
                # åˆ›å»ºèŠ‚ç‚¹
                original_id = node_event.get('id')
                created_node = await self.create_fault_knowledge_node(node_data)
                if created_node:
                    created_nodes[original_id] = created_node
                    
                    # æ˜¾ç¤ºè¿›åº¦å’Œæ—¶åºä¿¡æ¯
                    time_info = node_data.get('properties', {}).get('time', 'Unknown')
                    category = node_data.get('properties', {}).get('fault_category', 'Unknown')
                    logger.info(f"â° è¿›åº¦: {i}/{len(nodes)} - {time_info} - {category}")
                
                # æ§åˆ¶å¯¼å…¥é€Ÿåº¦
                await asyncio.sleep(0.1)
        
        logger.info(f"âœ… é˜¶æ®µä¸€å®Œæˆï¼šæˆåŠŸåˆ›å»º {len(created_nodes)} ä¸ªæ—¶åºèŠ‚ç‚¹")
        
        # è¾“å‡ºæ—¶é—´çº¿ç»Ÿè®¡
        await self.print_timeline_summary(created_nodes, timeline_stats, edges)
        
        logger.info("ğŸ‰ æ•…éšœæ—¶åºäº‹ä»¶å¯¼å…¥å®Œæˆï¼")
        logger.info("ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨æ—¶åºæŸ¥è¯¢åŠŸèƒ½åˆ†ææ•…éšœå½±å“é“¾å’Œæ¢å¤è¿‡ç¨‹")

    async def print_timeline_summary(self, created_nodes: dict, timeline_stats: dict, edges: list):
        """æ‰“å°æ—¶é—´çº¿ç»Ÿè®¡æ‘˜è¦"""
        logger.info("=" * 80)
        logger.info("ğŸ“Š æ•…éšœæ—¶åºäº‹ä»¶å¯¼å…¥ç»Ÿè®¡æ‘˜è¦")
        logger.info("=" * 80)
        
        # æ—¶é—´çº¿é˜¶æ®µç»Ÿè®¡
        logger.info("ğŸ”¢ æŒ‰æ—¶é—´çº¿é˜¶æ®µç»Ÿè®¡:")
        for phase, count in sorted(timeline_stats.items()):
            logger.info(f"  {phase}: {count} ä¸ªäº‹ä»¶")
        
        # æ•…éšœåˆ†ç±»ç»Ÿè®¡
        category_stats = {}
        for node in created_nodes.values():
            category = node.get('properties', {}).get('fault_category', 'å…¶ä»–')
            category_stats[category] = category_stats.get(category, 0) + 1
        
        logger.info("ğŸ·ï¸  æŒ‰æ•…éšœåˆ†ç±»ç»Ÿè®¡:")
        for category, count in category_stats.items():
            logger.info(f"  {category}: {count} ä¸ª")
        
        # æ—¶åºå…³ç³»ç»Ÿè®¡
        logger.info(f"ğŸ”— å› æœå…³ç³»: {len(edges)} æ¡æ—¶åºå…³è”")
        
        # æ—¶é—´èŒƒå›´
        times = []
        for node in created_nodes.values():
            time_str = node.get('properties', {}).get('time')
            if time_str:
                try:
                    times.append(datetime.fromisoformat(time_str.replace('Z', '+00:00')))
                except:
                    pass
        
        if times:
            times.sort()
            start_time = times[0]
            end_time = times[-1]
            duration = end_time - start_time
            
            logger.info(f"â³ æ•…éšœæ—¶é—´çº¿èŒƒå›´:")
            logger.info(f"  å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info(f"  ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info(f"  æ€»æ—¶é•¿: {duration}")
        
        logger.info(f"ğŸ“ˆ æ€»è®¡å¯¼å…¥æ—¶åºèŠ‚ç‚¹: {len(created_nodes)} ä¸ª")
        logger.info("=" * 80)
        
        # æŸ¥è¯¢å»ºè®®
        logger.info("ğŸ” æ¨èæ—¶åºæŸ¥è¯¢åœºæ™¯:")
        logger.info("  1. åœ¨ Temporal Explorer ä¸­è®¾ç½®æ—¶é—´èŒƒå›´: 2025-09-01T08:15:00 ~ 08:35:00")
        logger.info("  2. Chat æŸ¥è¯¢: 'åˆ†æ 2025å¹´9æœˆ1æ—¥ä¸Šåˆçš„æ•…éšœæ—¶é—´çº¿'")
        logger.info("  3. Chat æŸ¥è¯¢: 'æ•…éšœæ¢å¤è¿‡ç¨‹çš„å„ä¸ªé˜¶æ®µç”¨äº†å¤šé•¿æ—¶é—´ï¼Ÿ'")
        logger.info("  4. Chat æŸ¥è¯¢: 'MTTDå’ŒMTTRåˆ†åˆ«æ˜¯å¤šå°‘ï¼Ÿ'")
        logger.info("  5. Chat æŸ¥è¯¢: 'æ ¹å› åˆ†æçš„ç»“è®ºæ˜¯ä»€ä¹ˆï¼Ÿ'")

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ”¥ TKG Context Engine - æ•…éšœæ—¶åºäº‹ä»¶å¯¼å…¥å·¥å…·")
    logger.info("ğŸ¯ ç›®æ ‡åœºæ™¯ï¼šæ•…éšœå½±å“é“¾åˆ†æã€MTTD/MTTRè®¡ç®—ã€æ ¹å› è¿½è¸ª")
    
    async with FaultTimelineImporter(API_BASE_URL) as importer:
        try:
            # æ£€æŸ¥APIè¿é€šæ€§
            response = await importer.client.get(f"{API_BASE_URL}/health")
            if response.status_code != 200:
                logger.error("âŒ åç«¯APIä¸å¯ç”¨ï¼Œè¯·ç¡®è®¤æœåŠ¡å·²å¯åŠ¨")
                return
            logger.info("âœ… åç«¯APIè¿æ¥æ­£å¸¸")
            
            # æ‰§è¡Œæ•°æ®å¯¼å…¥
            await importer.import_fault_timeline()
            
        except Exception as e:
            logger.error(f"âŒ å¯¼å…¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            raise

if __name__ == "__main__":
    asyncio.run(main())