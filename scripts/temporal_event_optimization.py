#!/usr/bin/env python3
"""
æ—¶åºäº‹ä»¶ä¼˜åŒ–å®ç°ç¤ºä¾‹ - åŸºäºå¢å¼ºè®¾è®¡é‡æ„æ•…éšœäº‹ä»¶

å±•ç¤ºå¦‚ä½•åˆ©ç”¨æ—¶åºçŸ¥è¯†å›¾è°±çš„ valid/invalid çŠ¶æ€ç‰¹æ€§è¿›è¡ŒåŠ¨æ€äº‹ä»¶ç®¡ç†

å…³é”®ä¼˜åŒ–ç‚¹ï¼š
1. åŠ¨æ€çŠ¶æ€è½¬æ¢ï¼šåŸºäºæ¡ä»¶è‡ªåŠ¨ valid â†’ invalid
2. æ—¶åºçº¦æŸå»ºæ¨¡ï¼šç²¾ç¡®çš„æ—¶é—´çª—å£å’Œä¾èµ–å…³ç³»  
3. ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼šå®Œæ•´çš„çŠ¶æ€å˜è¿å†å²
4. æ™ºèƒ½å¤±æ•ˆæ¡ä»¶ï¼šåŸºäºä¸šåŠ¡é€»è¾‘çš„è‡ªåŠ¨å¤±æ•ˆ
"""

import asyncio
import httpx
import json
from datetime import datetime, timedelta, timezone
from dataclasses import dataclass
from typing import Dict, List, Optional, Any
from enum import Enum
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

API_BASE_URL = "http://localhost:8001"

class TemporalEventType(str, Enum):
    FAULT_OCCURRENCE = "fault_occurrence"
    ALERT_LIFECYCLE = "alert_lifecycle"
    IMPACT_OBSERVATION = "impact_observation"
    RESPONSE_ACTION = "response_action"
    RECOVERY_PROCESS = "recovery_process"
    VALIDATION_CHECK = "validation_check"
    INCIDENT_RESOLUTION = "incident_resolution"

class ValidityState(str, Enum):
    PENDING = "pending"      # å¾…ç¡®è®¤
    VALID = "valid"         # æœ‰æ•ˆ
    INVALID = "invalid"     # æ— æ•ˆ
    EXPIRED = "expired"     # è¿‡æœŸ

@dataclass
class StateTransition:
    from_state: ValidityState
    to_state: ValidityState
    transition_time: datetime
    trigger: str
    reason: str
    automatic: bool = True

@dataclass
class TemporalEvent:
    """å¢å¼ºçš„æ—¶åºäº‹ä»¶"""
    event_id: str
    event_type: TemporalEventType
    name: str
    description: str
    
    # æ—¶åºä¿¡æ¯
    occurrence_time: datetime
    detection_time: Optional[datetime] = None
    validity_start: datetime = None
    validity_end: Optional[datetime] = None
    
    # çŠ¶æ€ç®¡ç†
    current_state: ValidityState = ValidityState.PENDING
    state_history: List[StateTransition] = None
    
    # å¤±æ•ˆæ¡ä»¶
    invalidation_conditions: List[str] = None
    validation_dependencies: List[str] = None
    
    # ä¸šåŠ¡å±æ€§
    confidence: float = 1.0
    severity: str = "INFO"
    impact_scope: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.state_history is None:
            self.state_history = []
        if self.invalidation_conditions is None:
            self.invalidation_conditions = []
        if self.validation_dependencies is None:
            self.validation_dependencies = []
        if self.impact_scope is None:
            self.impact_scope = {}
        if self.validity_start is None:
            self.validity_start = self.occurrence_time

class TemporalEventOptimizer:
    def __init__(self, api_base_url: str):
        self.api_base_url = api_base_url
        self.client = httpx.AsyncClient(timeout=30.0)
        
    async def __aenter__(self):
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.client.aclose()

    def create_optimized_fault_timeline(self) -> List[TemporalEvent]:
        """åˆ›å»ºä¼˜åŒ–çš„æ•…éšœæ—¶åºäº‹ä»¶"""
        base_time = datetime(2025, 9, 1, 8, 15, 30, tzinfo=timezone(timedelta(hours=9)))
        
        events = []
        
        # 1. æ•…éšœå‘ç”Ÿäº‹ä»¶ - æ¡ä»¶æ€§æœ‰æ•ˆ
        fault_event = TemporalEvent(
            event_id="FAULT-20250901-001",
            event_type=TemporalEventType.FAULT_OCCURRENCE,
            name="DATABASE_CONNECTION_TIMEOUT",
            description="æ•°æ®åº“è¿æ¥æ± è€—å°½å¯¼è‡´è¿æ¥è¶…æ—¶",
            occurrence_time=base_time,
            detection_time=base_time + timedelta(seconds=2),
            validity_start=base_time,
            validity_end=None,  # åŠ¨æ€ç¡®å®šï¼ŒåŸºäºæ•…éšœè§£å†³
            current_state=ValidityState.PENDING,
            invalidation_conditions=[
                "root_cause_resolved",
                "connection_pool_restarted", 
                "service_fully_recovered",
                "incident_officially_closed"
            ],
            validation_dependencies=[
                "multiple_monitoring_sources_confirm",
                "impact_assessment_completed"
            ],
            confidence=0.95,
            severity="CRITICAL",
            impact_scope={
                "affected_services": ["ittzp-auth-service-PRO"],
                "estimated_users": 50000,
                "business_functions": ["user_authentication", "session_management"],
                "sla_breach_risk": "high"
            }
        )
        events.append(fault_event)
        
        # 2. å‘Šè­¦äº‹ä»¶ - åŸºäºé˜ˆå€¼æ¢å¤å¤±æ•ˆ
        alert_event = TemporalEvent(
            event_id="ALERT-20250901-001",
            event_type=TemporalEventType.ALERT_LIFECYCLE,
            name="ERROR_RATE_SPIKE_CRITICAL",
            description="é”™è¯¯ç‡çªç ´é˜ˆå€¼13.75å€è§¦å‘P0å‘Šè­¦",
            occurrence_time=base_time + timedelta(seconds=15),
            validity_start=base_time + timedelta(seconds=15),
            validity_end=None,  # å½“é”™è¯¯ç‡æ¢å¤æ­£å¸¸æ—¶è‡ªåŠ¨å¤±æ•ˆ
            current_state=ValidityState.VALID,  # å‘Šè­¦ç«‹å³æœ‰æ•ˆ
            invalidation_conditions=[
                "error_rate_below_threshold_for_5min",
                "manual_alert_acknowledgment",
                "service_recovery_confirmed"
            ],
            confidence=1.0,  # å‘Šè­¦æ•°æ®é€šå¸¸æ˜¯ç¡®å®šçš„
            severity="P0",
            impact_scope={
                "threshold_exceeded": 13.75,
                "current_error_rate": 0.6875,
                "alert_channels": ["pagerduty", "slack", "email"]
            }
        )
        events.append(alert_event)
        
        # 3. å½±å“è§‚æµ‹äº‹ä»¶ - çŸ­æœŸæœ‰æ•ˆæ€§çª—å£
        impact_events = []
        observation_times = [
            (base_time, {"error_rate": 0.6875, "latency_ms": 5240.5, "status": "degraded"}),
            (base_time + timedelta(minutes=1), {"error_rate": 0.9, "latency_ms": 8500.0, "status": "critical"}),
            (base_time + timedelta(minutes=7, seconds=30), {"error_rate": 0.2623, "latency_ms": 1250.0, "status": "improving"}),
            (base_time + timedelta(minutes=11, seconds=30), {"error_rate": 0.0103, "latency_ms": 65.2, "status": "normal"})
        ]
        
        for i, (obs_time, metrics) in enumerate(observation_times):
            impact_event = TemporalEvent(
                event_id=f"IMPACT-OBS-{i+1:03d}",
                event_type=TemporalEventType.IMPACT_OBSERVATION,
                name=f"PERFORMANCE_METRICS_T{i+1}",
                description=f"ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡è§‚æµ‹: {metrics['status']}çŠ¶æ€",
                occurrence_time=obs_time,
                validity_start=obs_time,
                validity_end=obs_time + timedelta(minutes=15),  # 15åˆ†é’Ÿæœ‰æ•ˆæœŸ
                current_state=ValidityState.VALID,
                invalidation_conditions=[
                    "newer_observation_available",
                    "metrics_invalidated",
                    "observation_timeout"
                ],
                confidence=0.9,
                severity="INFO" if metrics['status'] == "normal" else "WARNING",
                impact_scope={
                    "metrics": metrics,
                    "observation_source": "APM_monitoring",
                    "reliability": "high"
                }
            )
            events.append(impact_event)
        
        # 4. å“åº”è¡ŒåŠ¨äº‹ä»¶ - æ‰§è¡ŒæœŸé—´æœ‰æ•ˆ
        response_event = TemporalEvent(
            event_id="RESPONSE-20250901-001",
            event_type=TemporalEventType.RESPONSE_ACTION,
            name="INCIDENT_RESPONSE_INITIATED",
            description="SRE-TEAM-Aå¯åŠ¨P0çº§äº‹æ•…å“åº”æµç¨‹",
            occurrence_time=base_time + timedelta(minutes=1, seconds=30),
            validity_start=base_time + timedelta(minutes=1, seconds=30),
            validity_end=base_time + timedelta(minutes=15),  # é¢„è®¡15åˆ†é’Ÿå“åº”å‘¨æœŸ
            current_state=ValidityState.VALID,
            invalidation_conditions=[
                "incident_resolved",
                "response_escalated",
                "response_timeout"
            ],
            validation_dependencies=[
                "alert_confirmed",
                "team_availability_verified"
            ],
            confidence=0.85,
            severity="HIGH",
            impact_scope={
                "response_team": "SRE-TEAM-A",
                "sla_target": "15_minutes",
                "escalation_path": "defined"
            }
        )
        events.append(response_event)
        
        # 5. æ¢å¤è¿‡ç¨‹äº‹ä»¶ - æ“ä½œæˆåŠŸåå¤±æ•ˆ
        recovery_event = TemporalEvent(
            event_id="RECOVERY-20250901-001",
            event_type=TemporalEventType.RECOVERY_PROCESS,
            name="CONNECTION_POOL_RESTART_OPERATION",
            description="æ‰§è¡Œæ•°æ®åº“è¿æ¥æ± é‡å¯æ¢å¤æ“ä½œ",
            occurrence_time=base_time + timedelta(minutes=4, seconds=30),
            validity_start=base_time + timedelta(minutes=4, seconds=30),
            validity_end=base_time + timedelta(minutes=9, seconds=30),  # 5åˆ†é’Ÿæ“ä½œçª—å£
            current_state=ValidityState.VALID,
            invalidation_conditions=[
                "recovery_operation_completed",
                "recovery_operation_failed",
                "operation_timeout"
            ],
            validation_dependencies=[
                "root_cause_identified",
                "recovery_plan_approved",
                "change_management_cleared"
            ],
            confidence=0.8,  # æ¢å¤æ“ä½œæœ‰ä¸ç¡®å®šæ€§
            severity="HIGH",
            impact_scope={
                "operation_type": "service_restart",
                "estimated_downtime": "5_minutes", 
                "risk_assessment": "low",
                "rollback_plan": "available"
            }
        )
        events.append(recovery_event)
        
        # 6. éªŒè¯æ£€æŸ¥äº‹ä»¶ - éªŒè¯å®Œæˆåå¤±æ•ˆ
        validation_event = TemporalEvent(
            event_id="VALIDATION-20250901-001",
            event_type=TemporalEventType.VALIDATION_CHECK,
            name="RECOVERY_SMOKE_TESTS",
            description="æ‰§è¡Œæ¢å¤ååŠŸèƒ½éªŒè¯å’Œå†’çƒŸæµ‹è¯•",
            occurrence_time=base_time + timedelta(minutes=9, seconds=30),
            validity_start=base_time + timedelta(minutes=9, seconds=30),
            validity_end=base_time + timedelta(minutes=12),  # 2.5åˆ†é’ŸéªŒè¯çª—å£
            current_state=ValidityState.VALID,
            invalidation_conditions=[
                "validation_tests_completed",
                "validation_failed",
                "validation_timeout"
            ],
            validation_dependencies=[
                "recovery_operation_completed",
                "service_responding"
            ],
            confidence=0.95,
            severity="INFO",
            impact_scope={
                "test_suites": ["auth_login_flow", "token_validation", "db_connectivity"],
                "success_criteria": "95%_pass_rate",
                "validation_scope": "critical_functions"
            }
        )
        events.append(validation_event)
        
        # 7. äº‹æ•…è§£å†³äº‹ä»¶ - æ°¸ä¹…æœ‰æ•ˆè®°å½•
        resolution_event = TemporalEvent(
            event_id="RESOLUTION-20250901-001",
            event_type=TemporalEventType.INCIDENT_RESOLUTION,
            name="INCIDENT_OFFICIALLY_RESOLVED",
            description="äº‹æ•…æ­£å¼å®£å‘Šè§£å†³ï¼ŒæœåŠ¡å®Œå…¨æ¢å¤æ­£å¸¸",
            occurrence_time=base_time + timedelta(minutes=14, seconds=30),
            validity_start=base_time + timedelta(minutes=14, seconds=30),
            validity_end=None,  # è§£å†³è®°å½•æ°¸ä¹…æœ‰æ•ˆ
            current_state=ValidityState.VALID,
            invalidation_conditions=[
                "resolution_disputed",
                "incident_reoccurred_within_24h"
            ],
            validation_dependencies=[
                "all_systems_restored",
                "validation_tests_passed",
                "stakeholder_confirmation"
            ],
            confidence=0.99,
            severity="INFO",
            impact_scope={
                "total_incident_duration": "14m30s",
                "affected_user_minutes": 725000,  # 50k users * 14.5 min
                "sla_status": "met",
                "business_impact": "minimal"
            }
        )
        events.append(resolution_event)
        
        return events

    def simulate_state_transitions(self, events: List[TemporalEvent]) -> Dict[str, List[StateTransition]]:
        """æ¨¡æ‹Ÿäº‹ä»¶çŠ¶æ€è½¬æ¢"""
        transitions = {}
        
        for event in events:
            event_transitions = []
            
            # åˆå§‹çŠ¶æ€è½¬æ¢
            if event.current_state == ValidityState.PENDING:
                # PENDING â†’ VALID è½¬æ¢
                valid_time = event.validity_start
                if event.validation_dependencies:
                    # æ¨¡æ‹Ÿä¾èµ–æ»¡è¶³åçš„å»¶è¿Ÿ
                    valid_time = event.occurrence_time + timedelta(seconds=30)
                
                event_transitions.append(StateTransition(
                    from_state=ValidityState.PENDING,
                    to_state=ValidityState.VALID,
                    transition_time=valid_time,
                    trigger="validation_dependencies_satisfied",
                    reason=f"ä¾èµ–æ¡ä»¶æ»¡è¶³: {', '.join(event.validation_dependencies)}",
                    automatic=True
                ))
            
            # å¤±æ•ˆè½¬æ¢ï¼ˆåŸºäºå¤±æ•ˆæ¡ä»¶ï¼‰
            if event.invalidation_conditions:
                invalid_time = self._calculate_invalidation_time(event)
                if invalid_time:
                    event_transitions.append(StateTransition(
                        from_state=ValidityState.VALID,
                        to_state=ValidityState.INVALID,
                        transition_time=invalid_time,
                        trigger="invalidation_condition_met",
                        reason=f"å¤±æ•ˆæ¡ä»¶è§¦å‘: {event.invalidation_conditions[0]}",
                        automatic=True
                    ))
            
            # è¿‡æœŸè½¬æ¢
            if event.validity_end:
                event_transitions.append(StateTransition(
                    from_state=ValidityState.VALID,
                    to_state=ValidityState.EXPIRED,
                    transition_time=event.validity_end,
                    trigger="validity_period_ended",
                    reason="æœ‰æ•ˆæœŸè‡ªç„¶ç»“æŸ",
                    automatic=True
                ))
            
            transitions[event.event_id] = event_transitions
        
        return transitions

    def _calculate_invalidation_time(self, event: TemporalEvent) -> Optional[datetime]:
        """è®¡ç®—äº‹ä»¶å¤±æ•ˆæ—¶é—´"""
        base_time = datetime(2025, 9, 1, 8, 15, 30, tzinfo=timezone(timedelta(hours=9)))
        
        # åŸºäºäº‹ä»¶ç±»å‹å’Œå¤±æ•ˆæ¡ä»¶è®¡ç®—å¤±æ•ˆæ—¶é—´
        if event.event_type == TemporalEventType.FAULT_OCCURRENCE:
            # æ•…éšœåœ¨è§£å†³æ—¶å¤±æ•ˆ
            return base_time + timedelta(minutes=14, seconds=30)
        elif event.event_type == TemporalEventType.ALERT_LIFECYCLE:
            # å‘Šè­¦åœ¨æœåŠ¡æ¢å¤æ—¶å¤±æ•ˆ
            return base_time + timedelta(minutes=14, seconds=45)
        elif event.event_type == TemporalEventType.RECOVERY_PROCESS:
            # æ¢å¤æ“ä½œåœ¨å®Œæˆæ—¶å¤±æ•ˆ
            return base_time + timedelta(minutes=7, seconds=30)
        elif event.event_type == TemporalEventType.VALIDATION_CHECK:
            # éªŒè¯åœ¨å®Œæˆæ—¶å¤±æ•ˆ
            return base_time + timedelta(minutes=11, seconds=30)
        
        return None

    def generate_temporal_queries(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ—¶åºæŸ¥è¯¢ç¤ºä¾‹"""
        base_time = datetime(2025, 9, 1, 8, 15, 30, tzinfo=timezone(timedelta(hours=9)))
        
        queries = [
            {
                "description": "æ•…éšœå‘ç”Ÿæ—¶åˆ»çš„æœ‰æ•ˆäº‹ä»¶",
                "query_time": base_time,
                "expected_states": ["FAULT-äº‹ä»¶PENDING", "å…¶ä»–äº‹ä»¶æœªå‘ç”Ÿ"]
            },
            {
                "description": "å‘Šè­¦è§¦å‘åçš„äº‹ä»¶çŠ¶æ€",
                "query_time": base_time + timedelta(minutes=2),
                "expected_states": ["FAULT-VALID", "ALERT-VALID", "IMPACT-VALID"]
            },
            {
                "description": "æ¢å¤æ“ä½œæœŸé—´çš„æœ‰æ•ˆäº‹ä»¶", 
                "query_time": base_time + timedelta(minutes=6),
                "expected_states": ["FAULT-VALID", "ALERT-VALID", "RECOVERY-VALID", "RESPONSE-VALID"]
            },
            {
                "description": "äº‹æ•…è§£å†³åçš„äº‹ä»¶çŠ¶æ€",
                "query_time": base_time + timedelta(minutes=16),
                "expected_states": ["RESOLUTION-VALID", "å…¶ä»–å…³é”®äº‹ä»¶-INVALID"]
            },
            {
                "description": "24å°æ—¶åçš„å†å²äº‹ä»¶çŠ¶æ€",
                "query_time": base_time + timedelta(days=1),
                "expected_states": ["å¤§éƒ¨åˆ†äº‹ä»¶-EXPIRED", "RESOLUTION-VALID"]
            }
        ]
        
        return queries

    async def create_knowledge_node_with_temporal(self, event: TemporalEvent) -> dict:
        """åˆ›å»ºå¸¦æ—¶åºä¿¡æ¯çš„çŸ¥è¯†èŠ‚ç‚¹"""
        node_data = {
            "name": event.name,
            "type": "event",
            "content": f"{event.description} [æ—¶åºäº‹ä»¶ç±»å‹: {event.event_type.value}]",
            "properties": {
                "event_id": event.event_id,
                "event_type": event.event_type.value,
                "occurrence_time": event.occurrence_time.isoformat(),
                "detection_time": event.detection_time.isoformat() if event.detection_time else None,
                "current_state": event.current_state.value,
                "confidence": event.confidence,
                "severity": event.severity,
                "impact_scope": event.impact_scope,
                "invalidation_conditions": event.invalidation_conditions,
                "validation_dependencies": event.validation_dependencies,
                "temporal_optimization": "enabled"
            },
            "valid_time": {
                "start_time": event.validity_start.isoformat(),
                "end_time": event.validity_end.isoformat() if event.validity_end else None
            },
            "effective_time": event.occurrence_time.isoformat()
        }
        
        try:
            response = await self.client.post(
                f"{self.api_base_url}/api/knowledge/",
                json=node_data,
                headers={"Content-Type": "application/json"}
            )
            response.raise_for_status()
            result = response.json()
            logger.info(f"âœ… åˆ›å»ºæ—¶åºä¼˜åŒ–èŠ‚ç‚¹: {event.name} [{event.current_state.value}]")
            return result
        except httpx.HTTPError as e:
            logger.error(f"âŒ åˆ›å»ºèŠ‚ç‚¹å¤±è´¥: {e}")
            return None

    async def demonstrate_temporal_optimization(self):
        """æ¼”ç¤ºæ—¶åºä¼˜åŒ–æ•ˆæœ"""
        logger.info("ğŸš€ å¼€å§‹æ—¶åºäº‹ä»¶ä¼˜åŒ–æ¼”ç¤º")
        logger.info("=" * 80)
        
        # 1. åˆ›å»ºä¼˜åŒ–çš„äº‹ä»¶
        events = self.create_optimized_fault_timeline()
        logger.info(f"ğŸ“… åˆ›å»ºäº† {len(events)} ä¸ªä¼˜åŒ–çš„æ—¶åºäº‹ä»¶")
        
        # 2. æ¨¡æ‹ŸçŠ¶æ€è½¬æ¢
        transitions = self.simulate_state_transitions(events)
        logger.info("ğŸ”„ æ¨¡æ‹Ÿäº‹ä»¶çŠ¶æ€è½¬æ¢ï¼š")
        for event_id, trans_list in transitions.items():
            for trans in trans_list:
                logger.info(f"   {event_id}: {trans.from_state.value} â†’ {trans.to_state.value} "
                          f"@ {trans.transition_time.strftime('%H:%M:%S')} ({trans.reason})")
        
        # 3. å¯¼å…¥ä¼˜åŒ–çš„äº‹ä»¶åˆ°ç³»ç»Ÿ
        logger.info("\nğŸ“¦ å¯¼å…¥ä¼˜åŒ–äº‹ä»¶åˆ°çŸ¥è¯†å›¾è°±ï¼š")
        created_nodes = []
        for event in events:
            node = await self.create_knowledge_node_with_temporal(event)
            if node:
                created_nodes.append(node)
            await asyncio.sleep(0.1)
        
        # 4. ç”Ÿæˆæ—¶åºæŸ¥è¯¢ç¤ºä¾‹
        queries = self.generate_temporal_queries()
        logger.info(f"\nğŸ” ç”Ÿæˆ {len(queries)} ä¸ªæ—¶åºæŸ¥è¯¢ç¤ºä¾‹ï¼š")
        for i, query in enumerate(queries, 1):
            logger.info(f"   {i}. {query['description']}")
            logger.info(f"      æŸ¥è¯¢æ—¶é—´: {query['query_time'].strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info(f"      é¢„æœŸçŠ¶æ€: {', '.join(query['expected_states'])}")
        
        # 5. è¾“å‡ºä¼˜åŒ–æ•ˆæœæ€»ç»“
        self.print_optimization_summary(events, transitions, created_nodes)

    def print_optimization_summary(self, events: List[TemporalEvent], 
                                 transitions: Dict[str, List[StateTransition]], 
                                 created_nodes: List[dict]):
        """æ‰“å°ä¼˜åŒ–æ•ˆæœæ€»ç»“"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š æ—¶åºäº‹ä»¶ä¼˜åŒ–æ•ˆæœæ€»ç»“")
        logger.info("=" * 80)
        
        # äº‹ä»¶ç±»å‹ç»Ÿè®¡
        event_types = {}
        for event in events:
            event_types[event.event_type.value] = event_types.get(event.event_type.value, 0) + 1
        
        logger.info("ğŸ·ï¸  äº‹ä»¶ç±»å‹åˆ†å¸ƒ:")
        for event_type, count in event_types.items():
            logger.info(f"   {event_type}: {count} ä¸ª")
        
        # çŠ¶æ€è½¬æ¢ç»Ÿè®¡
        total_transitions = sum(len(trans_list) for trans_list in transitions.values())
        logger.info(f"ğŸ”„ æ€»çŠ¶æ€è½¬æ¢æ•°: {total_transitions}")
        
        # æ—¶åºç‰¹æ€§ç»Ÿè®¡
        conditional_events = len([e for e in events if e.invalidation_conditions])
        dependent_events = len([e for e in events if e.validation_dependencies])
        
        logger.info("âš¡ æ—¶åºç‰¹æ€§ç»Ÿè®¡:")
        logger.info(f"   æ¡ä»¶æ€§å¤±æ•ˆäº‹ä»¶: {conditional_events}/{len(events)}")
        logger.info(f"   ä¾èµ–éªŒè¯äº‹ä»¶: {dependent_events}/{len(events)}")
        logger.info(f"   æˆåŠŸå¯¼å…¥èŠ‚ç‚¹: {len(created_nodes)}/{len(events)}")
        
        logger.info("\nğŸ¯ ä¼˜åŒ–æ”¹è¿›ç‚¹:")
        logger.info("   âœ… åŠ¨æ€çŠ¶æ€è½¬æ¢: äº‹ä»¶çŠ¶æ€åŸºäºä¸šåŠ¡æ¡ä»¶è‡ªåŠ¨å˜åŒ–")
        logger.info("   âœ… ç²¾ç¡®æ—¶åºçº¦æŸ: æ¯ä¸ªäº‹ä»¶æœ‰æ˜ç¡®çš„æœ‰æ•ˆæ—¶é—´çª—å£")
        logger.info("   âœ… æ™ºèƒ½å¤±æ•ˆæœºåˆ¶: åŸºäºä¸šåŠ¡é€»è¾‘çš„è‡ªåŠ¨å¤±æ•ˆæ¡ä»¶")
        logger.info("   âœ… ç”Ÿå‘½å‘¨æœŸç®¡ç†: å®Œæ•´è®°å½•äº‹ä»¶ä»äº§ç”Ÿåˆ°æ¶ˆäº¡")
        logger.info("   âœ… ä¸Šä¸‹æ–‡æ„ŸçŸ¥: ä¸°å¯Œçš„å½±å“èŒƒå›´å’Œä¾èµ–å…³ç³»ä¿¡æ¯")
        
        logger.info("\nğŸ’¡ åº”ç”¨ä»·å€¼:")
        logger.info("   ğŸ” ç²¾ç¡®æ—¶ç‚¹æŸ¥è¯¢: æŸ¥è¯¢ä»»æ„æ—¶åˆ»çš„æœ‰æ•ˆäº‹ä»¶é›†åˆ")
        logger.info("   ğŸ“ˆ åŠ¨æ€åˆ†æ: è¿½è¸ªäº‹ä»¶æœ‰æ•ˆæ€§éšæ—¶é—´çš„å˜åŒ–")
        logger.info("   ğŸ§  æ™ºèƒ½æ¨ç†: åŸºäºçŠ¶æ€è½¬æ¢è¿›è¡Œå› æœæ¨ç†")
        logger.info("   ğŸ“‹ å®Œæ•´å®¡è®¡: æä¾›äº‹ä»¶ç”Ÿå‘½å‘¨æœŸçš„å®Œæ•´å†å²")
        
        logger.info("=" * 80)

async def main():
    """ä¸»æ¼”ç¤ºç¨‹åº"""
    logger.info("ğŸ”¥ TKG Context Engine - æ—¶åºäº‹ä»¶ä¼˜åŒ–æ¼”ç¤º")
    
    async with TemporalEventOptimizer(API_BASE_URL) as optimizer:
        try:
            # æ£€æŸ¥APIè¿é€šæ€§
            response = await optimizer.client.get(f"{API_BASE_URL}/health")
            if response.status_code != 200:
                logger.error("âŒ åç«¯APIä¸å¯ç”¨")
                return
            logger.info("âœ… åç«¯APIè¿æ¥æ­£å¸¸")
            
            # æ‰§è¡Œä¼˜åŒ–æ¼”ç¤º
            await optimizer.demonstrate_temporal_optimization()
            
        except Exception as e:
            logger.error(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            raise

if __name__ == "__main__":
    asyncio.run(main())